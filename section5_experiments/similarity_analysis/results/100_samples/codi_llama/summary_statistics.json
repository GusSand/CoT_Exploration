{
  "experiment_info": {
    "timestamp": "20251026_191638",
    "model": "meta-llama/Llama-3.2-1B-Instruct",
    "checkpoint": "../models/CODI-llama3.2-1b",
    "dataset": "zen-E/GSM8k-Aug",
    "num_continuous_thoughts": 6,
    "use_projection": true,
    "greedy_decoding": true,
    "extended_metrics": [
      "cosine_similarity",
      "normalized_l2_distance"
    ]
  },
  "overall_results": {
    "total_examples": 100,
    "correct_predictions": 37,
    "incorrect_predictions": 63,
    "accuracy": 0.37
  },
  "step_correctness_analysis": {
    "1_steps": {
      "count": 1,
      "avg_step_accuracy": 0.0
    },
    "2_steps": {
      "count": 15,
      "avg_step_accuracy": 0.4
    },
    "3_steps": {
      "count": 11,
      "avg_step_accuracy": 0.1515151515151515
    },
    "4_steps": {
      "count": 6,
      "avg_step_accuracy": 0.2916666666666667
    },
    "5_steps": {
      "count": 3,
      "avg_step_accuracy": 0.3333333333333333
    }
  },
  "similarity_analysis": {
    "avg_cosine_sim_all": 0.11182536969866072,
    "std_cosine_sim_all": 0.029054484274883025,
    "avg_cosine_sim_top1": 0.15318429129464287,
    "avg_norm_l2_dist_all": 1.3327734375,
    "std_norm_l2_dist_all": 0.022135885521119985,
    "avg_norm_l2_dist_top1": 1.3012053571428572
  },
  "output_locations": {
    "correct_predictions": "outputs/section5_analysis_extended/section5_extended_20251026_191638/correct_predictions/predictions.json",
    "incorrect_predictions": "outputs/section5_analysis_extended/section5_extended_20251026_191638/incorrect_predictions/predictions.json"
  }
}